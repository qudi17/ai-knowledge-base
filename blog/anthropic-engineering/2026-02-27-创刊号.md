# Anthropic Engineering 周报 - 创刊号

**日期**: 2026-02-27  
**来源**: https://www.anthropic.com/engineering  
**解读视角**: 系统架构师（RAG 方案负责人）

---

## 文章一：Effective Context Engineering for AI Agents

**链接**: https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents  
**发布时间**: 2025-09-29

### 一句话总结
上下文工程是提示工程的自然演进，核心在于优化有限上下文窗口中的 token 配置，以最小的注意力预算换取最大的模型效能。

### 核心内容

1. **上下文衰减（Context Rot）问题**
   - 随着上下文 token 数量增加，模型准确回忆信息的能力下降
   - 所有模型都存在注意力预算限制，每个新 token 都会消耗预算
   - Transformer 架构的 n² 成对关系导致上下文长度与注意力聚焦存在天然张力

2. **有效上下文的解剖学**
   - 系统提示应处于"Goldilocks 区"：避免过度硬编码的脆弱逻辑，也避免过于模糊的高层指导
   - 工具设计原则：自包含、容错、用途清晰，避免功能重叠的工具集膨胀
   - 示例（Few-shot）应 curated 多样化、规范化的案例，而非罗列所有边界情况

3. **运行时上下文检索策略**
   - "Just-in-Time"上下文：维护轻量级引用（文件路径、查询、链接），运行时动态加载
   - 混合策略：部分数据预加载保证速度，部分自主探索保持灵活
   - 渐进式披露：让 Agent 通过探索逐层发现相关上下文

4. **长周期任务的三种技术**
   - **压缩（Compaction）**: 总结对话内容，重启新上下文窗口
   - **结构化笔记（Structured Note-Taking）**: Agent 定期写入外部持久化记忆
   - **多 Agent 架构**: 主 Agent 协调，子 Agent 专注任务，返回浓缩摘要

### 架构师洞察

- **核心范式转变**: 从"如何写好提示"转向"如何管理整个上下文状态"
- **注意力是稀缺资源**: 必须像管理数据库连接池一样管理上下文 token
- **混合检索是未来**: 预索引 + 自主探索的平衡点取决于任务特性
- **记忆外部化是关键**: 长周期任务必须将状态持久化到上下文之外

### 实践建议

**公司场景（RAG 方案）**:
- 实现上下文压缩机制：定期总结对话历史，保留架构决策和未解决 Bug
- 设计工具集时遵循"最小可用集"原则，避免工具膨胀导致 Agent 决策困难
- 采用文件化记忆策略：让 Agent 维护 NOTES.md 或 TODO.md 跟踪复杂任务进度
- 评估多 Agent 架构：复杂研究任务可拆分为探索子 Agent + 综合主 Agent

**个人场景**:
- 为个人知识库设计"轻量引用 + 按需加载"的检索模式
- 使用 Claude 的 Memory Tool 维护个人项目状态跨会话持久化
- 长文档处理时采用分层摘要策略，避免一次性加载全文

---

## 文章二：Introducing Contextual Retrieval

**链接**: https://www.anthropic.com/engineering/contextual-retrieval  
**发布时间**: 2024-09-19

### 一句话总结
Contextual Retrieval 通过在检索前为每个文本块添加上下文解释，将 RAG 检索失败率降低 49%，结合重排序后可降低 67%。

### 核心内容

1. **传统 RAG 的上下文丢失问题**
   - 文档分块后丢失整体上下文，导致检索时无法准确匹配
   - 示例：SEC  filings 分块后"公司营收增长 3%"无法关联到具体公司和时间

2. **Contextual Retrieval 双技术**
   - **Contextual Embeddings**: 为每个 chunk  prepend  chunk 特定的解释性上下文
   - **Contextual BM25**: 对添加上下文后的 chunk 建立 BM25 索引
   - 使用 Claude 自动生成上下文（50-100 tokens），提示词提供标准化模板

3. **性能提升数据**
   - Contextual Embeddings 单独降低检索失败率 35%（5.7% → 3.7%）
   - Contextual Embeddings + Contextual BM25 降低 49%（5.7% → 2.9%）
   - 加上 Reranking 后降低 67%（5.7% → 1.9%）

4. **成本优化**
   - 利用 Claude 的 Prompt Caching 特性，一次性缓存文档，重复引用
   - 预处理成本：约$1.02 per million document tokens

### 架构师洞察

- **检索质量决定 RAG 上限**: 再强的生成模型也无法基于错误检索产生正确答案
- **上下文是检索的一等公民**: 不应在分块时丢弃文档级元信息
- **混合检索是标配**: Embedding（语义）+ BM25（精确）+ Reranking（重排序）三层架构
- **预处理投资回报高**: 一次性生成上下文，永久提升检索质量

### 实践建议

**公司场景（RAG 方案）**:
- 立即实施 Contextual Retrieval：使用官方 cookbook 模板生成 chunk 上下文
- 采用三层检索架构：Embedding + BM25 初检 → Reranking 精选 → Top-20 送入 LLM
- 针对企业文档定制上下文生成提示词：加入公司术语表、业务领域知识
- 评估 Prompt Caching 降低成本：高频访问文档缓存后重复使用

**个人场景**:
- 个人知识库分块时手动或自动添加文档级元信息（来源、时间、主题）
- 使用 Voyage 或 Gemini Embedding 模型获得最佳效果
- 实验不同 chunk 大小（400-800 tokens）和重叠率对检索质量的影响

---

## 文章三：Building Effective Agents

**链接**: https://www.anthropic.com/engineering/building-effective-agents  
**发布时间**: 2024-12-19

### 一句话总结
成功的 Agent 实现不依赖复杂框架，而是基于简单、可组合的模式：从 Augmented LLM 到 Workflow 再到 Autonomous Agent，按需增加复杂度。

### 核心内容

1. **Agent 定义与分类**
   - **Workflows**: LLM 和工具通过预定义代码路径编排
   - **Agents**: LLM 动态自主决定流程和工具使用
   - 核心区别：控制权的归属（预定义 vs 模型自主）

2. **五种核心 Workflow 模式**
   - **Prompt Chaining**: 任务分解为顺序步骤，每步处理上一步输出
   - **Routing**: 分类输入并路由到专门处理流程
   - **Parallelization**: Sectioning（任务分块）+ Voting（多视角投票）
   - **Orchestrator-Workers**: 中央 LLM 动态分解任务，委派给 Worker
   - **Evaluator-Optimizer**: 生成 - 评估 - 反馈循环迭代优化

3. **Agent 实施三原则**
   - 保持设计简洁：从简单提示开始，仅在必要时增加复杂度
   - 优先透明性：显式展示 Agent 规划步骤
   - 精心打造 ACI（Agent-Computer Interface）：工具文档和测试同等重要

4. **工具设计最佳实践**
   - 给模型足够 token"思考"，避免把自己逼入死角
   - 格式接近互联网自然文本，减少格式化开销
   - 像为初级开发者写文档一样设计工具描述
   - Poka-yoke（防错）设计：修改参数使错误更难发生

### 架构师洞察

- **简单性优先**: 最成功的实现往往不使用复杂框架，而是直接调用 LLM API
- **模式可组合**: 五种 Workflow 模式可灵活组合，根据任务特征选择
- **工具即接口**: ACI（Agent-Computer Interface）的重要性不亚于 HCI
- **评估驱动迭代**: 任何复杂度增加必须有可量化的效果提升

### 实践建议

**公司场景（RAG 方案）**:
- 评估现有 RAG 流程：是否可用 Prompt Chaining 分解为"检索→过滤→生成"三步
- 实施路由模式：简单查询用 Haiku，复杂查询用 Sonnet 优化成本
- 设计工具时投入与人类界面同等精力：清晰的工具描述、示例、边界条件
- 建立评估体系：任何 Agent 改进必须有量化指标（准确率、延迟、成本）

**个人场景**:
- 个人自动化任务优先尝试单次 LLM 调用 + 检索，再考虑多步 Agent
- 使用 Evaluator-Optimizer 模式迭代个人写作或翻译任务
- 为常用工具（文件操作、API 调用）编写详细的使用示例和边界说明

---

## 本周行动建议

### 行动 1：评估现有 RAG 检索质量（优先级：高）
- 抽样 50 个真实用户查询，计算当前检索的 Recall@20
- 对比 Contextual Retrieval 的预期提升（理论可降低 49% 失败率）
- 时间投入：2-3 小时

### 行动 2：实现 Contextual Retrieval 原型（优先级：高）
- 使用官方 cookbook（https://platform.claude.com/cookbook/capabilities-contextual-embeddings-guide）
- 选择一个小规模知识库（<1000 文档）进行实验
- 对比实验前后检索质量和最终生成质量
- 时间投入：4-6 小时

### 行动 3：设计 Agent 工具集规范（优先级：中）
- 为团队制定工具设计模板：描述、参数、示例、边界条件
- 审查现有工具集，识别功能重叠和模糊边界
- 实施 Poka-yoke 改进：修改易错参数设计
- 时间投入：3-4 小时

---

## 参考资料

- [Contextual Retrieval Cookbook](https://platform.claude.com/cookbook/capabilities-contextual-embeddings-guide)
- [Memory and Context Management Cookbook](https://platform.claude.com/cookbook/tool-use-memory-cookbook)
- [Agents Basic Workflows](https://platform.claude.com/cookbook/patterns-agents-basic-workflows)
- [Model Context Protocol](https://modelcontextprotocol.io/)

---

*本期周报由 AI 辅助生成，下期预告：Anthropic 多 Agent 研究系统深度解析*
