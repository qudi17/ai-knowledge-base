---
tags: [rag, retrieval, contextual, solution-design]
created: 2026-02-28
type: solution-design
status: draft
---

# Contextual Retrieval 技术方案 - 100 万研报 RAG 系统

**学习来源**：Anthropic Engineering Blog - Contextual Retrieval  
**学习日期**：2026-02-28  
**应用场景**：100 万份上市公司研究报告 RAG 系统  
**文档类型**：技术方案设计（可落地）

---

## 📊 执行摘要

### 核心价值主张

**Contextual Retrieval** 是 Anthropic 2024 年提出的 RAG 优化技术，通过为每个 chunk 添加上下文信息，显著提升检索准确率。

**关键数据**（Anthropic 实验）：
- 检索失败率降低 **49%**（仅 Contextual Retrieval）
- 检索失败率降低 **67%**（+ Reranking）
- 预处理成本：**$1.02 / 百万文档 tokens**（一次性，使用 Prompt Caching）

---

### 本方案核心建议

| 方案 | 推荐度 | 说明 |
|------|-------|------|
| **优化 Chunking** | ⭐⭐⭐⭐⭐ | 必须做，按段落/章节切分 |
| **Contextual Retrieval** | ⭐⭐⭐⭐ | 建议做，先小范围验证 |
| **Reranking** | ⭐⭐⭐ | 可选，根据效果决定 |
| **组合方案** | ⭐⭐⭐⭐⭐ | 优化 chunking + Contextual Retrieval |

---

## 🎯 问题定义

### 传统 RAG 的核心问题

**问题**：文档分块后丢失上下文，导致检索失败

**具体例子**：
```
完整文档："贵州茅台 2023 年年报：营收同比增长 25%，达到 50 亿元"
        ↓ 分块（800 tokens）
Chunk："营收同比增长 25%，达到 50 亿元"
        ↓ 丢失信息
- 公司名：❌（贵州茅台）
- 报告期：❌（2023 年）
- 文档类型：❌（年报）

用户搜索："贵州茅台 2023 年 营收"
结果：检索失败 ❌（chunk 里没有"贵州茅台"和"2023"）
```

**影响**：
- 用户查询与 chunk 内容不匹配
- 即使语义相关，也无法检索到
- 检索失败率约 5-10%（取决于文档类型）

---

## 💡 Contextual Retrieval 方案

### 核心思路

**为每个 chunk 添加 chunk-specific 的上下文信息**

**转换示例**：
```
原始 Chunk:
"营收同比增长 25%，达到 50 亿元"

Contextualized Chunk:
"[上下文] 贵州茅台 (600519.SH) 2024 年深度研究报告，
财务分析章节，2023 年年报数据。
[正文] 营收同比增长 25%，达到 50 亿元"
```

### 技术架构

```
┌─────────────────────────────────────────────────────┐
│              预处理阶段                              │
├─────────────────────────────────────────────────────┤
│  1. 文档分块（800 tokens/chunk）                     │
│  2. 生成上下文（Claude，50-100 tokens）              │
│     Prompt：                                         │
│     "请为这个 chunk 生成简短的上下文说明，            │
│      包含公司名、代码、报告日期、章节名"             │
│  3. Prepend 上下文到 chunk                           │
│  4. 创建 Embedding 和 BM25 索引                       │
└─────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────┐
│              检索阶段                                │
├─────────────────────────────────────────────────────┤
│  1. 用户查询 → 查询解析和扩展                        │
│  2. BM25 + Embedding 联合检索（top-150）             │
│  3. （可选）Reranking（top-20）                      │
│  4. 返回结果                                        │
└─────────────────────────────────────────────────────┘
```

---

## 🏗️ 100 万研报场景设计

### 场景特点分析

| 特点 | 影响 | 应对策略 |
|------|------|---------|
| **100 万文档** | 大规模索引 | 分布式 ES，10+ 分片 |
| **研究报告** | 结构化强 | 分层索引（报告级 + chunk 级） |
| **已提取内容** | 跳过 PDF 解析 | 直接索引 |
| **公司/代码** | 关键检索维度 | 字段加权 BM25 |
| **财务数据** | 数值表达多样 | 归一化处理 |

---

### 索引结构设计

**双层索引策略**：

```
┌─────────────────────────────────────┐
│  报告级索引（Coarse-grained）       │
│  - 用途：初步筛选相关报告            │
│  - 字段：公司名、代码、日期、摘要    │
│  - 规模：100 万文档                  │
└─────────────────────────────────────┘
              ↓
┌─────────────────────────────────────┐
│  Chunk 级索引（Fine-grained）        │
│  - 用途：精确检索内容                │
│  - 字段：contextualized_content、    │
│         chunk_content、章节          │
│  - 规模：1000 万 chunks（~10 个/chunk）│
└─────────────────────────────────────┘
```

---

### BM25 字段加权设计

**核心设计**：

```python
字段权重：
{
    "stock_code": 10.0,        # 股票代码，最精确
    "company_name": 5.0,       # 公司名
    "contextualized_content": 5.0,  # 上下文内容（关键！）
    "section": 3.0,            # 章节标题
    "industry": 3.0,           # 行业
    "chunk_content": 1.0,      # 原始内容
}

# ES 查询示例
{
  "multi_match": {
    "query": "贵州茅台 营收 2023",
    "fields": [
      "stock_code^10",
      "company_name^5",
      "contextualized_content^5",
      "section^3",
      "chunk_content^1"
    ]
  }
}
```

---

### 查询处理流程

**用户查询不能直接丢给 ES**，需要处理：

```
用户查询："帮我找一下茅台 2023 年的营收数据"
        ↓ 查询解析
{
  companies: ["茅台", "贵州茅台"],
  stock_codes: ["600519.SH"],
  metrics: ["营收", "营业收入"],
  time: ["2023 年", "2023 年年度报告"]
}
        ↓ 查询扩展
{
  companies: ["茅台", "贵州茅台", "600519", "Kweichow Moutai"],
  metrics: ["营收", "营业收入", "revenue", "销售收入"]
}
        ↓ ES 检索
BM25 + 字段加权 + 过滤条件
```

---

## 💰 成本估算

### 预处理成本（一次性）

**假设**：
- 100 万份报告
- 每份报告 8,000 tokens
- 每份报告 ~10 个 chunks
- 每个 chunk 上下文 100 tokens

**使用 Prompt Caching**：
```
文档加载成本：100 万 × 8,000 tokens = 80 亿 tokens
上下文生成成本：1000 万 × 100 tokens = 10 亿 tokens

总成本（Claude Haiku）：
= (80 亿 + 10 亿) / 100 万 × $0.0001
= $9,000（一次性）

使用 Prompt Caching 优化后：
≈ $1.02 / 百万文档 tokens × 8000 百万
≈ $8,160（一次性）
```

**时间估算**：
```
上下文生成速度：~100 chunks/秒
1000 万 chunks：~28 小时
```

---

### 存储成本（持续）

**索引规模**：
```
1000 万 chunks × ~1KB/chunk（含上下文）
= ~10GB（压缩后）

ES 存储（3 副本）：
= 10GB × 3 = 30GB
```

**云成本估算**（AWS）：
```
EBS gp3: $0.08/GB/月
30GB × $0.08 = $2.4/月
```

---

### 检索成本（持续）

**假设**：
- 日均 1 万次查询
- 每次查询检索 top-20 chunks

**ES 检索成本**：
```
1 万次/天 × 30 天 × $0.0001/次 = $30/月
```

**（可选）Reranking 成本**：
```
1 万次/天 × 30 天 × 150 chunks × $0.00001/chunk
= $450/月（Cohere Rerank）
```

---

## 📋 实施路线图

### 阶段 1：快速验证（1-2 周）

**目标**：验证 Contextual Retrieval 效果

**任务**：
- [ ] 选 1000 份报告做试点
- [ ] 实现基础 BM25 索引（Whoosh/ES）
- [ ] 实现上下文生成（Claude API）
- [ ] 对比实验：
  - 方案 A：仅优化 chunking
  - 方案 B：优化 chunking + Contextual Retrieval
- [ ] 评估检索准确率提升

**成功标准**：
- 检索失败率降低 > 20%
- 单文档预处理成本 < $0.01

---

### 阶段 2：生产部署（4-6 周）

**目标**：100 万报告全量索引

**任务**：
- [ ] 部署 Elasticsearch 集群（10+ 分片）
- [ ] 实现查询处理管道（解析 + 扩展）
- [ ] 实现字段加权 BM25
- [ ] 全量预处理（~28 小时）
- [ ] 性能优化（缓存、并发）
- [ ] 监控和告警

**成功标准**：
- 检索延迟 < 300ms（P95）
- 系统可用性 > 99.9%

---

### 阶段 3：持续优化（持续）

**任务**：
- [ ] 收集用户查询日志
- [ ] 分析检索失败案例
- [ ] 调整上下文生成 prompt
- [ ] 优化 BM25 参数（k1, b）
- [ ] （可选）添加 Reranking

---

## 📊 效果评估方案

### 评估指标

| 指标 | 定义 | 目标 |
|------|------|------|
| **检索失败率** | 相关文档未进入 top-20 的比例 | < 3% |
| **MRR** | 第一个相关结果的排名倒数 | > 0.8 |
| **NDCG@20** | 排序质量 | > 0.85 |
| **检索延迟** | P95 延迟 | < 300ms |
| **用户满意度** | 点赞/点踩比例 | > 4.5/5 |

---

### 测试数据集

**构建方法**：
1. 从历史查询日志中抽取 500 个查询
2. 人工标注相关文档（每查询 5-10 个）
3. 划分为训练集（300）+ 验证集（100）+ 测试集（100）

**查询类型分布**：
- 公司 + 指标（40%）："茅台 2023 年 营收"
- 公司 + 时间（20%）："宁德时代 2024Q1"
- 指标 + 行业（20%）："毛利率 食品饮料 行业"
- 对比查询（10%）："茅台 vs 五粮液"
- 其他（10%）

---

## ⚠️ 风险与缓解

### 技术风险

| 风险 | 概率 | 影响 | 缓解措施 |
|------|------|------|---------|
| 上下文生成质量差 | 中 | 高 | 人工审核样本，优化 prompt |
| 检索延迟超标 | 中 | 中 | 缓存热门查询，优化索引 |
| 成本超预算 | 低 | 中 | 分阶段实施，持续监控 |
| 中文支持不佳 | 中 | 高 | 使用中文优化模型 |

---

### 业务风险

| 风险 | 缓解措施 |
|------|---------|
| 用户不接受新搜索方式 | A/B 测试，逐步 rollout |
| 数据更新延迟 | 增量索引，每日更新 |
| 合规问题 | 数据脱敏，访问控制 |

---

## 🔗 相关资源

### 官方资源
- [Anthropic Blog](https://www.anthropic.com/engineering/contextual-retrieval)
- [Cookbook](https://platform.claude.com/cookbook/capabilities-contextual-embeddings-guide)
- [Appendix Data](https://assets.anthropic.com/m/1632cded0a125333/original/Contextual-Retrieval-Appendix-2.pdf)

### 技术参考
- [Elasticsearch BM25](https://www.elastic.co/guide/en/elasticsearch/reference/current/similarity.bm25.html)
- [Cohere Rerank](https://cohere.com/rerank)
- [Voyage Reranker](https://docs.voyageai.com/docs/reranker)

---

## 📝 学习心得（费曼验证总结）

### 核心洞察

1. **上下文是关键**：传统 RAG 的问题不是 embedding 不够好，而是输入本身就丢失了上下文

2. **工程思维**：不是盲目追求 SOTA，而是考虑性价比和 ROI

3. **组合方案最优**：优化 chunking + Contextual Retrieval，而非二选一

4. **必须做评估**：论文数据是特定条件下的，实际效果需要自己验证

---

### 批判性思考

**论文数据的局限性**：
- 实验数据集：代码库、小说、ArXiv 论文
- 未包含：金融研报、结构化文档
- Chunk 策略：固定 800 tokens
- 未对比：优化 chunking 的效果

**实际应用建议**：
- ✅ 先小范围验证（1000 份报告）
- ✅ 对比实验（有/无 Contextual Retrieval）
- ✅ 根据自己的数据调优
- ✅ 持续监控和迭代

---

## 🎯 决策建议

### 推荐方案

**对于 100 万研报 RAG 系统**：

```
阶段 1（1-2 周）：
- 实施：优化 chunking（按段落/章节）
- 验证：基础检索效果
- 成本：低

阶段 2（2-4 周）：
- 实施：Contextual Retrieval（小范围）
- 验证：检索准确率提升
- 成本：中（$100-200 测试）

阶段 3（4-6 周）：
- 决策：如果提升 > 20%，全量部署
- 实施：100 万报告全量索引
- 成本：高（$8,000-10,000 一次性）

阶段 4（可选）：
- 实施：Reranking
- 验证：进一步提升效果
- 成本：中（$450/月）
```

---

### Go/No-Go 决策点

**阶段 1 后决策**：
- 如果基础检索准确率 > 90% → 可能不需要 Contextual Retrieval
- 如果基础检索准确率 < 85% → 继续阶段 2

**阶段 2 后决策**：
- 如果准确率提升 > 20% → 全量部署
- 如果准确率提升 < 10% → 重新评估

---

**文档版本**：v1.0  
**创建日期**：2026-02-28  
**作者**：Jarvis（基于与 Eddy 的讨论）  
**状态**：Draft（待阶段 1 验证后更新）  
**下次 Review**：2026-03-14
