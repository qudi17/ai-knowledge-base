# nanobot æ ¸å¿ƒæ¨¡å—è¯¦è§£

## ğŸ“¦ æ¨¡å—æ¦‚è§ˆ

```mermaid
graph TB
    subgraph "æ ¸å¿ƒæ¨¡å—"
        AL[AgentLoop]
        CB[ContextBuilder]
        MS[MemoryStore]
        SK[SkillsLoader]
        SM[SubagentManager]
        SS[SessionManager]
    end
    
    subgraph "æ•°æ®å­˜å‚¨"
        S1[Session JSONL]
        S2[MEMORY.md]
        S3[HISTORY.md]
        S4[Skillsç›®å½•]
        S5[Bootstrapæ–‡ä»¶]
    end
    
    AL -->|è°ƒç”¨| CB
    AL -->|è°ƒç”¨| MS
    AL -->|è°ƒç”¨| SK
    AL -->|è°ƒç”¨| SM
    AL -->|è¯»å†™| SS
    
    CB -.è¯»å–.-> S5
    CB -.è¯»å–.-> S2
    CB -.è¯»å–.-> S4
    CB -.è¯»å–.-> S3
    
    MS -.è¯»å†™.-> S2
    MS -.è¯»å†™.-> S3
    
    SK -.è¯»å–.-> S4
    
    SS -.è¯»å†™.-> S1
    
    SM -.åˆ›å»ºç‹¬ç«‹session.-> SS
    
    style AL fill:#fff4e1
    style CB fill:#e1f5ff
    style MS fill:#e1ffe1
```

---

## ğŸ”„ AgentLoop - æ ¸å¿ƒå¤„ç†å¼•æ“

### ç±»ç»“æ„

```python
class AgentLoop:
    def __init__(
        self,
        bus: MessageBus,              # æ¶ˆæ¯æ€»çº¿
        provider: LLMProvider,          # LLMæä¾›è€…
        workspace: Path,                # å·¥ä½œåŒºè·¯å¾„
        model: str | None = None,       # æ¨¡å‹åç§°
        max_iterations: int = 40,        # æœ€å¤§è¿­ä»£æ¬¡æ•°
        temperature: float = 0.1,       # æ¸©åº¦å‚æ•°
        max_tokens: int = 4096,          # æœ€å¤§tokenæ•°
        memory_window: int = 100,        # è®°å¿†çª—å£
        brave_api_key: str | None = None, # Braveæœç´¢å¯†é’¥
        exec_config: ExecToolConfig,     # Shellé…ç½®
        cron_service: CronService,        # å®šæ—¶ä»»åŠ¡æœåŠ¡
        restrict_to_workspace: bool = False, # å·¥ä½œåŒºé™åˆ¶
        session_manager: SessionManager,    # ä¼šè¯ç®¡ç†å™¨
        mcp_servers: dict,              # MCPæœåŠ¡å™¨é…ç½®
        channels_config: ChannelsConfig,   # Channelé…ç½®
    ):
        # åˆå§‹åŒ–ç»„ä»¶
        self.context = ContextBuilder(workspace)
        self.sessions = session_manager or SessionManager(workspace)
        self.tools = ToolRegistry()
        self.subagents = SubagentManager(...)
        
        # çŠ¶æ€ç®¡ç†
        self._running = False
        self._processing_lock = asyncio.Lock()
        self._consolidating: set[str] = set()
        self._active_tasks: dict[str, list[asyncio.Task]] = {}
        
        # æ³¨å†Œé»˜è®¤å·¥å…·
        self._register_default_tools()
```

### æ ¸å¿ƒæ–¹æ³•è¯¦è§£

#### 1. run() - ä¸»å¾ªç¯

```python
async def run(self) -> None:
    self._running = True
    await self._connect_mcp()  # è¿æ¥MCPæœåŠ¡å™¨
    logger.info("Agent loop started")
    
    while self._running:
        try:
            # 1ç§’è¶…æ—¶å…è®¸ä¼˜é›…é€€å‡º
            msg = await asyncio.wait_for(
                self.bus.consume_inbound(),
                timeout=1.0
            )
        except asyncio.TimeoutError:
            continue
        
        # ç‰¹æ®Šå‘½ä»¤æ£€æŸ¥
        if msg.content.strip().lower() == "/stop":
            await self._handle_stop(msg)
        else:
            # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡å¤„ç†æ¶ˆæ¯
            task = asyncio.create_task(self._dispatch(msg))
            self._active_tasks.setdefault(msg.session_key, []).append(task)
            
            # ä»»åŠ¡å®Œæˆåæ¸…ç†
            task.add_done_callback(
                lambda t, k=msg.session_key: self._active_tasks.get(k, []) and self._active_tasks[k].remove(t)
            )
```

**å…³é”®ç‚¹ï¼š**
- âœ… è¶…æ—¶æœºåˆ¶é¿å…æ°¸ä¹…é˜»å¡
- âœ… å¼‚æ­¥ä»»åŠ¡è°ƒåº¦ä¿æŒå“åº”æ€§
- âœ… ä»»åŠ¡è·Ÿè¸ªä¸æ¸…ç†é˜²æ­¢å†…å­˜æ³„æ¼
- âœ… `/stop` å‘½ä»¤æ”¯æŒå–æ¶ˆæ‰€æœ‰ä»»åŠ¡

#### 2. _process_message() - æ¶ˆæ¯å¤„ç†

```python
async def _process_message(
    self,
    msg: InboundMessage,
    session_key: str | None = None,
    on_progress: Callable[[str], Awaitable[None]] | None = None,
) -> OutboundMessage | None:
    """å¤„ç†å•æ¡æ¶ˆæ¯å¹¶è¿”å›å“åº”"""
    
    # ç³»ç»Ÿæ¶ˆæ¯ç‰¹æ®Šè·¯ç”±
    if msg.channel == "system":
        channel, chat_id = msg.chat_id.split(":", 1)
        session = self.sessions.get_or_create(f"{channel}:{chat_id}")
        self._set_tool_context(channel, chat_id, msg.metadata.get("message_id"))
        history = session.get_history(max_messages=self.memory_window)
        messages = self.context.build_messages(
            history=history,
            current_message=msg.content,
            channel=channel, chat_id=chat_id
        )
        final_content, _, all_msgs = await self._run_agent_loop(messages)
        self._save_turn(session, all_msgs, 1 + len(history))
        self.sessions.save(session)
        return OutboundMessage(channel=channel, chat_id=chat_id, content=final_content)
    
    # å¸¸è§„æ¶ˆæ¯å¤„ç†
    preview = msg.content[:80] + "..." if len(msg.content) > 80 else msg.content
    logger.info("Processing message from {}:{}: {}", msg.channel, msg.sender_id, preview)
    
    key = session_key or msg.session_key
    session = self.sessions.get_or_create(key)
    
    # å‘½ä»¤åˆ¤æ–­
    cmd = msg.content.strip().lower()
    if cmd == "/new":
        # æ–°ä¼šè¯ï¼ˆè®°å¿†åˆå¹¶ + æ¸…ç©ºï¼‰
        ...
    elif cmd == "/help":
        # æ˜¾ç¤ºå¸®åŠ©
        ...
    else:
        # è®°å¿†åˆå¹¶æ£€æŸ¥ï¼ˆåå°ï¼‰
        unconsolidated = len(session.messages) - session.last_consolidated
        if unconsolidated >= self.memory_window:
            self._consolidating.add(session.key)
            _task = asyncio.create_task(self._consolidate_memory_background(session))
            self._consolidation_tasks.add(_task)
        
        # æ„å»ºä¸Šä¸‹æ–‡ä¸å¤„ç†
        self._set_tool_context(msg.channel, msg.chat_id, msg.metadata.get("message_id"))
        history = session.get_history(max_messages=self.memory_window)
        initial_messages = self.context.build_messages(
            history=history,
            current_message=msg.content,
            media=msg.media if msg.media else None,
            channel=msg.channel, chat_id=msg.chat_id
        )
        
        # è¿è¡ŒAgentå¾ªç¯
        async def _bus_progress(content: str, *, tool_hint: bool = False):
            meta = dict(msg.metadata or {})
            meta["_progress"] = True
            meta["_tool_hint"] = tool_hint
            await self.bus.publish_outbound(OutboundMessage(
                channel=msg.channel, chat_id=msg.chat_id, content=content, metadata=meta
            ))
        
        final_content, _, all_msgs = await self._run_agent_loop(
            initial_messages, on_progress=on_progress or _bus_progress
        )
        
        # ä¿å­˜è½®æ¬¡
        self._save_turn(session, all_msgs, 1 + len(history))
        self.sessions.save(session)
        
        # æ£€æŸ¥æ˜¯å¦å·²ä½¿ç”¨messageå·¥å…·
        if message_tool := self.tools.get("message"):
            if isinstance(message_tool, MessageTool) and message_tool._sent_in_turn:
                return None  # ä¸é‡å¤å‘é€
        
        return OutboundMessage(
            channel=msg.channel, chat_id=msg.chat_id, content=final_content, metadata=msg.metadata or {}
        )
```

#### 3. _run_agent_loop() - LLMä¸å·¥å…·å¾ªç¯

```python
async def _run_agent_loop(
    self,
    initial_messages: list[dict],
    on_progress: Callable[..., Awaitable[None]] | None = None,
) -> tuple[str | None, list[str], list[dict]]:
    """è¿è¡ŒAgentè¿­ä»£å¾ªç¯
    
    Returns:
        (final_content, tools_used, messages)
    """
    messages = initial_messages
    iteration = 0
    final_content = None
    tools_used: list[str] = []
    
    while iteration < self.max_iterations:
        iteration += 1
        
        # LLMè°ƒç”¨
        response = await self.provider.chat(
            messages=messages,
            tools=self.tools.get_definitions(),
            model=self.model,
            temperature=self.temperature,
            max_tokens=self.max_tokens
        )
        
        if response.has_tool_calls:
            # å‘é€è¿›åº¦åé¦ˆ
            if on_progress:
                clean = self._strip_think(response.content)
                if clean:
                    await on_progress(clean)
                await on_progress(self._tool_hint(response.tool_calls), tool_hint=True)
            
            # è½¬æ¢ä¸ºOpenAIæ ¼å¼
            tool_call_dicts = [
                {
                    "id": tc.id,
                    "type": "function",
                    "function": {
                        "name": tc.name,
                        "arguments": json.dumps(tc.arguments, ensure_ascii=False)
                    }
                }
                for tc in response.tool_calls
            ]
            
            # æ·»åŠ assistantæ¶ˆæ¯
            messages = self.context.add_assistant_message(
                messages, response.content, tool_call_dicts,
                reasoning_content=response.reasoning_content
            )
            
            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            for tool_call in response.tool_calls:
                tools_used.append(tool_call.name)
                args_str = json.dumps(tool_call.arguments, ensure_ascii=False)
                logger.info("Tool call: {}({})", tool_call.name, args_str[:200])
                
                # âš¡ æ ¸å¿ƒï¼šå·¥å…·æ‰§è¡Œ
                result = await self.tools.execute(tool_call.name, tool_call.arguments)
                
                messages = self.context.add_tool_result(
                    messages, tool_call.id, tool_call.name, result
                )
        else:
            # æ— å·¥å…·è°ƒç”¨ï¼Œå®Œæˆ
            clean = self._strip_think(response.content)
            messages = self.context.add_assistant_message(
                messages, clean, reasoning_content=response.reasoning_content
            )
            final_content = clean
            break
    
    # è¾¾åˆ°æœ€å¤§è¿­ä»£
    if final_content is None and iteration >= self.max_iterations:
        logger.warning("Max iterations ({}) reached", self.max_iterations)
        final_content = (
            f"I reached to the maximum number of tool call iterations ({self.max_iterations}) "
            "without completing the task. You can try breaking of task into smaller steps."
        )
    
    return final_content, tools_used, messages
```

---

## ğŸ¨ ContextBuilder - ä¸Šä¸‹æ–‡æ„å»ºå™¨

### ç³»ç»Ÿæç¤ºè¯åˆ†å±‚

```mermaid
graph TD
    System[build_system_prompt] --> Identity[_get_identity]
    System --> Bootstrap[_load_bootstrap_files]
    System --> Memory[memory.get_memory_context]
    System --> Always[skills.get_always_skills]
    System --> Summary[skills.build_skills_summary]
    
    Bootstrap --> BF1[AGENTS.md]
    Bootstrap --> BF2[SOUL.md]
    Bootstrap --> BF3[USER.md]
    Bootstrap --> BF4[TOOLS.md]
    
    Memory --> MF[MEMORY.md]
    
    Always --> AS1[åŠ è½½SKILL.md]
    
    Summary --> SS[æ„å»ºXMLæ¦‚è§ˆ]
    
    Identity --> Layer1[ç¬¬1å±‚: èº«ä»½]
    Bootstrap --> Layer2[ç¬¬2å±‚: å¼•å¯¼]
    Memory --> Layer3[ç¬¬3å±‚: é•¿æœŸè®°å¿†]
    Always --> Layer4[ç¬¬4å±‚: å¸¸ç”¨æŠ€èƒ½]
    Summary --> Layer5[ç¬¬5å±‚: æŠ€èƒ½æ¦‚è§ˆ]
    
    Layer1 --> Final[ç»„è£…å®Œæ•´prompt]
    Layer2 --> Final
    Layer3 --> Final
    Layer4 --> Final
    Layer5 --> Final
```

### Identityæ„å»ºè¯¦è§£

```python
def _get_identity(self) -> str:
    """è·å–æ ¸å¿ƒèº«ä»½éƒ¨åˆ†"""
    workspace_path = str(self.workspace.expanduser().resolve())
    system = platform.system()
    runtime = f"{'macOS' if system == 'Darwin' else system} {platform.machine()}, Python {platform.python_version()}"
    
    return f"""# nanobot ğŸˆ

You are nanobot, a helpful AI assistant.

## Runtime
{runtime}

## Workspace
Your workspace is at: {workspace_path}
- Long-term memory: {workspace_path}/memory/MEMORY.md
- History log: {workspace_path}/memory/HISTORY.md
- Custom skills: {workspace_path}/skills/{{skill-name}}/SKILL.md

## nanobot Guidelines
- State intent before tool calls, but NEVER predict or claim results before receiving them.
- Before modifying a file, read it first. Do not assume files or directories exist.
- After writing or editing a file, re-read it if accuracy matters.
- If a tool call fails, analyze error before retrying with a different approach.
- Ask for clarification when request is ambiguous.

Reply directly with text for conversations. Only use 'message' tool to send to a specific chat channel."""
```

### Bootstrapæ–‡ä»¶åŠ è½½

```python
def _load_bootstrap_files(self) -> str:
    """åŠ è½½æ‰€æœ‰å¼•å¯¼æ–‡ä»¶"""
    parts = []
    
    for filename in self.BOOTSTRAP_FILES:  # ["AGENTS.md", "SOUL.md", "USER.md", "TOOLS.md", "IDENTITY.md"]
        file_path = self.workspace / filename
        if file_path.exists():
            content = file_path.read_text(encoding="utf-8")
            parts.append(f"## {filename}\n\n{content}")
    
    return "\n\n".join(parts) if parts else ""
```

**Bootstrapæ–‡ä»¶ä½œç”¨ï¼š**

| æ–‡ä»¶ | ä½œç”¨ | ä¼˜å…ˆçº§ |
|------|------|--------|
| `IDENTITY.md` | è¦†ç›–é»˜è®¤èº«ä»½å®šä¹‰ | æœ€é«˜ |
| `AGENTS.md` | Agentè§’è‰²å®šä¹‰ | é«˜ |
| `SOUL.md` | Agentæ€§æ ¼ç‰¹å¾ | é«˜ |
| `USER.md` | ç”¨æˆ·ä½¿ç”¨åå¥½ | ä¸­ |
| `TOOLS.md` | å·¥å…·ä½¿ç”¨æŒ‡å— | ä¸­ |

### æ¶ˆæ¯ç»„è£…

```python
def build_messages(
    self,
    history: list[dict[str, Any]],
    current_message: str,
    skill_names: list[str] | None = None,
    media: list[str] | None = None,
    channel: str | None = None,
    chat_id: str | None = None,
) -> list[dict[str, Any]]:
    """æ„å»ºå®Œæ•´æ¶ˆæ¯åˆ—è¡¨"""
    return [
        {"role": "system", "content": self.build_system_prompt(skill_names)},
        *history,  # å†å²æ¶ˆæ¯
        {"role": "user", "content": self._build_runtime_context(channel, chat_id)},
        {"role": "user", "content": self._build_user_content(current_message, media)},
    ]
```

---

## ğŸ’¾ MemoryStore - åŒå±‚è®°å¿†ç³»ç»Ÿ

### è®°å¿†æ¶æ„

```mermaid
graph TB
    subgraph "åŒå±‚è®°å¿†"
        LT[é•¿æœŸè®°å¿† MEMORY.md]
        HL[å†å²æ—¥å¿— HISTORY.md]
    end
    
    subgraph "æ•°æ®æµ"
        S[Session.messages]
        U[æœªåˆå¹¶æ¶ˆæ¯<br/>unconsolidated]
        C[å·²åˆå¹¶ç´¢å¼•<br/>last_consolidated]
    end
    
    S -->|å½“unconsolidated<br/>&ge;memory_window| MC[MergeStore.consolidate]
    
    MC -->|ä¸“ç”¨LLM prompt| LLM[LLMåˆ†æå¯¹è¯]
    
    LLM -->|è¿”å›| Save1[history_entry<br/>â†’ HISTORY.md]
    LLM -->|è¿”å›| Save2[memory_update<br/>â†’ MEMORY.md]
    
    Save1 --> HL
    Save2 --> LT
    
    MC -->|æ›´æ–°| C[æ›´æ–°last_consolidated]
    
    style LT fill:#e1ffe1
    style HL fill:#e1f5ff
    style MC fill:#fff4e1
```

### consolidate()æ–¹æ³•è¯¦è§£

```python
async def consolidate(
    self,
    session: Session,
    provider: LLMProvider,
    model: str,
    *,
    archive_all: bool = False,
    memory_window: int = 50,
) -> bool:
    """åˆå¹¶æ—§æ¶ˆæ¯åˆ°MEMORY.md + HISTORY.md
    
    Returns:
        True on success (including no-op), False on failure
    """
    
    # 1. ç¡®å®šå¾…åˆå¹¶æ¶ˆæ¯
    if archive_all:
        old_messages = session.messages
        keep_count = 0
        logger.info("Memory consolidation (archive_all): {} messages", len(session.messages))
    else:
        keep_count = memory_window // 2
        if len(session.messages) <= keep_count:
            return True
        if len(session.messages) - session.last_consolidated <= 0:
            return True
        
        old_messages = session.messages[session.last_consolidated:-keep_count]
        if not old_messages:
            return True
        
        logger.info("Memory consolidation: {} to consolidate, {} keep", len(old_messages), keep_count)
    
    # 2. æ ¼å¼åŒ–å¯¹è¯å†å²
    lines = []
    for m in old_messages:
        if not m.get("content"):
            continue
        tools = f" [tools: {', '.join(m['tools_used'])}]" if m.get("tools_used") else ""
        lines.append(f"[{m.get('timestamp', '?')[:16]}] {m['role'].upper()}{tools}: {m['content']}")
    
    # 3. æ„å»ºåˆå¹¶prompt
    current_memory = self.read_long_term()
    prompt = f"""Process this conversation and call the save_memory tool with your consolidation.

## Current Long-term Memory
{current_memory or "(empty)"}

## Conversation to Process
{chr(10).join(lines)}"""
    
    # 4. LLMè°ƒç”¨
    try:
        response = await provider.chat(
            messages=[
                {"role": "system", "content": "You are a memory consolidation agent. Call the save_memory tool."},
                {"role": "user", "content": prompt}
            ],
            tools=_SAVE_MEMORY_TOOL,
            model=model,
        )
        
        if not response.has_tool_calls:
            logger.warning("Memory consolidation: LLM did not call save_memory")
            return False
        
        # 5. è§£æå¹¶ä¿å­˜
        args = response.tool_calls[0].arguments
        if isinstance(args, str):
            args = json.loads(args)
        
        # å†™å…¥HISTORY.md
        if entry := args.get("history_entry"):
            self.append_history(entry)
        
        # æ›´æ–°MEMORY.md
        if update := args.get("memory_update"):
            if update != current_memory:
                self.write_long_term(update)
        
        # 6. æ›´æ–°session
        session.last_consolidated = 0 if archive_all else len(session.messages) - keep_count
        logger.info("Memory consolidation done: {} messages, last_consolidated={}", len(session.messages), session.last_consolidated)
        return True
    except Exception:
        logger.exception("Memory consolidation failed")
        return False
```

---

## ğŸ§© SubagentManager - åå°ä»»åŠ¡ç®¡ç†

### Subagentç”Ÿå‘½å‘¨æœŸ

```mermaid
stateDiagram-v2
    [*] --> Spawn: spawn()è°ƒç”¨
    Spawn --> Running: åˆ›å»ºç‹¬ç«‹asyncio.Task
    Running --> Exec: ç®€åŒ–ç‰ˆAgentå¾ªç¯
    Exec --> Complete: è¾¾åˆ°15æ¬¡è¿­ä»£<br/>æˆ–æ— å·¥å…·è°ƒç”¨
    Complete --> Announce: é€šè¿‡buså‘é€ç³»ç»Ÿæ¶ˆæ¯
    Announce --> [*]: ä¸»ä»£ç†è‡ªç„¶æ€»ç»“
    
    Spawn --> Cancel: /stopå‘½ä»¤
    Running --> Cancel
    Cancel --> [*]: ä»»åŠ¡å–æ¶ˆ
```

### spawn()æ–¹æ³•

```python
async def spawn(
    self,
    task: str,
    label: str | None = None,
    origin_channel: str = "cli",
    origin_chat_id: str = "direct",
    session_key: str | None = None,
) -> str:
    """Spawnä¸€ä¸ªsubagentæ‰§è¡Œåå°ä»»åŠ¡"""
    task_id = str(uuid.uuid4())[:8]
    display_label = label or task[:30] + ("..." if len(task) > 30 else "")
    origin = {"channel": origin_channel, "chat_id": origin_chat_id}
    
    # åˆ›å»ºåå°ä»»åŠ¡
    bg_task = asyncio.create_task(
        self._run_subagent(task_id, task, display_label, origin)
    )
    
    # è·Ÿè¸ªä»»åŠ¡
    self._running_tasks[task_id] = bg_task
    if session_key:
        self._session_tasks.setdefault(session_key, set()).add(task_id)
    
    # æ¸…ç†å›è°ƒ
    def _cleanup(_: asyncio.Task) -> None:
        self._running_tasks.pop(task_id, None)
        if session_key and (ids := self._session_tasks.get(session_key)):
            ids.discard(task_id)
            if not ids:
                del self._session_tasks[session_key]
    
    bg_task.add_done_callback(_cleanup)
    
    logger.info("Spawned subagent [{}]: {}", task_id, display_label)
    return f"Subagent [{display_label}] started (id: {task_id}). I'll notify you when it completes."
```

### Subagent Prompt

```python
def _build_subagent_prompt(self, task: str) -> str:
    """æ„å»ºsubagentä¸“ç”¨prompt"""
    from datetime import datetime
    import time as _time
    now = datetime.now().strftime("%Y-%m-%d %H:%M (%A)")
    tz = _time.strftime("%Z") or "UTC"
    
    return f"""# Subagent

## Current Time
{now} ({tz})

You are a subagent spawned by the main agent to complete a specific task.

## Rules
1. Stay focused - complete only the assigned task, nothing else
2. Your final response will be reported back to the main agent
3. Do not initiate conversations or take on side tasks
4. Be concise but informative in your findings

## What You Can Do
- Read and write files in the workspace
- Execute shell commands
- Search the web and fetch web pages
- Complete the task thoroughly

## What You Cannot Do
- Send messages directly to users (no message tool available)
- Spawn other subagents
- Access the main agent's conversation history

## Workspace
Your workspace is at: {self.workspace}
Skills are available at: {self.workspace}/skills/ (read SKILL.md files as needed)

When you have completed the task, provide a clear summary of your findings or actions."""
```

---

## ğŸ“Š SessionManager - ä¼šè¯æŒä¹…åŒ–

### Sessionæ•°æ®æ¨¡å‹

```python
@dataclass
class Session:
    key: str                          # "telegram:123456"
    messages: list[dict[str, Any]]     # JSONLæ ¼å¼çš„æ¶ˆæ¯åˆ—è¡¨
    created_at: datetime                 # åˆ›å»ºæ—¶é—´
    updated_at: datetime                 # æ›´æ–°æ—¶é—´
    metadata: dict[str, Any]            # æ‰©å±•å…ƒæ•°æ®
    last_consolidated: int               # å·²åˆå¹¶æ¶ˆæ¯ç´¢å¼•ï¼ˆ0è¡¨ç¤ºå…¨éƒ¨ï¼‰
    
    def add_message(self, role: str, content: str, **kwargs) -> None:
        """æ·»åŠ æ¶ˆæ¯åˆ°session"""
        msg = {
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat(),
            **kwargs
        }
        self.messages.append(msg)
        self.updated_at = datetime.now()
    
    def get_history(self, max_messages: int = 500) -> list[dict]:
        """è¿”å›æœªåˆå¹¶æ¶ˆæ¯ç”¨äºLLMè¾“å…¥"""
        unconsolidated = self.messages[self.last_consolidated:]
        sliced = unconsolidated[-max_messages:]
        
        # ç¡®ä¿ä»¥useræ¶ˆæ¯å¼€å§‹
        for i, m in enumerate(sliced):
            if m.get("role") == "user":
                sliced = sliced[i:]
                break
        
        # æ¸…ç†ä¸éœ€è¦çš„å­—æ®µ
        out: list[dict] = []
        for m in sliced:
            entry: dict = {"role": m["role"], "content": m.get("content", "")}
            for k in ("tool_calls", "tool_call_id", "name"):
                if k in m:
                    entry[k] = m[k]
            out.append(entry)
        return out
    
    def clear(self) -> None:
        """æ¸…ç©ºæ‰€æœ‰æ¶ˆæ¯å¹¶é‡ç½®session"""
        self.messages = []
        self.last_consolidated = 0
        self.updated_at = datetime.now()
```

### JSONLæ ¼å¼ä¼˜åŠ¿

```jsonl
{"_type":"metadata","key":"telegram:123","created_at":"2026-02-26T10:00:00","last_consolidated":0}
{"role":"user","content":"Hello","timestamp":"2026-02-26T10:00:01"}
{"role":"assistant","content":"Hi!","timestamp":"2026-02-26T10:00:02"}
{"role":"tool","name":"read_file","content":"...","timestamp":"2026-02-26T10:00:03"}
```

**ä¸ºä»€ä¹ˆé€‰æ‹©JSONLï¼Ÿ**

| ç‰¹æ€§ | JSONL | ä¼˜ç‚¹ |
|------|-------|------|
| å¢é‡è¿½åŠ  | âœ… | æ— éœ€é‡å†™æ•´ä¸ªæ–‡ä»¶ |
| æµå¼å†™å…¥ | âœ… | é€‚åˆå®æ—¶æ—¥å¿— |
| æŒ‰è¡Œè¯»å– | âœ… | æ˜“äºgrepå’Œåˆ†æ |
| LLMå…¼å®¹ | âœ… | OpenAI APIæ”¯æŒ |
| æ–‡æœ¬å‹å¥½ | âœ… | äººç±»å¯è¯» |

---

## ğŸ¯ å…³é”®è®¾è®¡æ¨¡å¼æ€»ç»“

### 1. é”æœºåˆ¶

```python
# å…¨å±€å¤„ç†é”
self._processing_lock = asyncio.Lock()

async def _dispatch(self, msg: InboundMessage):
    async with self._processing_lock:  # åŒä¸€sessionä¸²è¡Œå¤„ç†
        await self._process_message(msg)
```

### 2. åå°ä»»åŠ¡è°ƒåº¦

```python
# åˆ›å»ºä¸é˜»å¡çš„åå°ä»»åŠ¡
async def _consolidate_and_unlock():
    async with lock:
        await self._consolidate_memory(session)

_task = asyncio.create_task(_consolidate_and_unlock())
self._consolidation_tasks.add(_task)
```

### 3. ä¼šè¯ç¼“å­˜

```python
# å†…å­˜ç¼“å­˜é¿å…é‡å¤è¯»å–ç£ç›˜
self._cache: dict[str, Session] = {}

def get_or_create(self, key: str) -> Session:
    if key in self._cache:
        return self._cache[key]
    
    session = self._load(key) or Session(key=key)
    self._cache[key] = session
    return session
```

### 4. å·¥å…·ä¸Šä¸‹æ–‡ä¼ é€’

```python
def _set_tool_context(self, channel: str, chat_id: str, message_id: str | None) -> None:
    """æ›´æ–°éœ€è¦è·¯ç”±ä¿¡æ¯çš„å·¥å…·ä¸Šä¸‹æ–‡"""
    if message_tool := self.tools.get("message"):
        message_tool.set_context(channel, chat_id, message_id)
    
    if spawn_tool := self.tools.get("spawn"):
        spawn_tool.set_context(channel, chat_id)
```

---

## ğŸš€ æ€§èƒ½ä¼˜åŒ–ç‚¹

| ä¼˜åŒ– | å®ç° | æ•ˆæœ |
|------|------|------|
| **Sessionç¼“å­˜** | `_cache: dict` | é¿å…é‡å¤ç£ç›˜I/O |
| **åå°åˆå¹¶** | `asyncio.create_task()` | ä¸é˜»å¡ä¸»å¯¹è¯ |
| **å·¥å…·ç»“æœæˆªæ–­** | 500å­—ç¬¦é™åˆ¶ | å‡å°‘LLM context |
| **å›¾ç‰‡å ä½ç¬¦** | `[image]`æ›¿ä»£base64 | èŠ‚çœtokenæˆæœ¬ |
| **Promptç¼“å­˜** | Anthropic `cache_control` | é™ä½APIè´¹ç”¨ |
| **ä»»åŠ¡å–æ¶ˆ** | `/stop`å‘½ä»¤ | ç«‹å³é‡Šæ”¾èµ„æº |

---

## ğŸ“ è°ƒè¯•æŠ€å·§

### 1. å¯ç”¨è¯¦ç»†æ—¥å¿—

```bash
# Agentè¿è¡Œæ—¶æ˜¾ç¤ºæ—¥å¿—
nanobot agent --logs

# Gatewayè¿è¡Œæ—¶æ˜¾ç¤ºæ—¥å¿—
nanobot gateway --verbose
```

### 2. æ£€æŸ¥Sessionå†…å®¹

```bash
# æŸ¥çœ‹æœ€è¿‘ä¼šè¯
cat ~/.nanobot/workspace/sessions/*.jsonl | tail -50
```

### 3. æ‰‹åŠ¨è§¦å‘è®°å¿†åˆå¹¶

```bash
# åœ¨å¯¹è¯ä¸­å‘é€
/new
```

### 4. ç›‘æ§èµ„æºä½¿ç”¨

```python
# æ·»åŠ åˆ°AgentLoop.__init__
logger.info("Active sessions: {}", len(self._active_tasks))
logger.info("Running subagents: {}", self.subagents.get_running_count())
logger.info("Consolidating: {}", len(self._consolidating))
```

---

## ğŸš€ ä¸‹ä¸€æ­¥å­¦ä¹ 

- **å¤šå¹³å°é›†æˆ** â†’ [05-å¤šå¹³å°é›†æˆ.md](./05-å¤šå¹³å°é›†æˆ.md)
- **æ‰©å±•å¼€å‘æŒ‡å—** â†’ [06-æ‰©å±•å¼€å‘æŒ‡å—.md](./06-æ‰©å±•å¼€å‘æŒ‡å—.md)
