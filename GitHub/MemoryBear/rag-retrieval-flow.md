# MemoryBear - RAG æ£€ç´¢æµç¨‹æ·±åº¦ç ”ç©¶

**ç ”ç©¶æ—¥æœŸ**ï¼š2026-02-28  
**ç ”ç©¶æ–¹æ³•**ï¼šæ¯›çº¿å›¢ç ”ç©¶æ³•ï¼ˆYarn Ball Methodï¼‰  
**å…¥å£ç‚¹**ï¼š`Input_Summary` node â†’ `SearchService.execute_hybrid_search()`

---

## ğŸ§¶ çº¿å¤´ï¼ˆå…¥å£ç‚¹ï¼‰

**ä½ç½®**ï¼š[`app/core/memory/agent/langgraph_graph/nodes/summary_nodes.py#L178`](https://github.com/qudi17/MemoryBear/blob/main/api/app/core/memory/agent/langgraph_graph/nodes/summary_nodes.py#L178)

**å…¥å£å‡½æ•°**ï¼š
```python
async def Input_Summary(state: ReadState) -> ReadState:
    # æœç´¢å‚æ•°
    search_params = {
        "end_user_id": end_user_id,
        "question": data,
        "return_raw_results": True,
        "include": ["summaries"]  # Only search summary nodes
    }
    
    # æ‰§è¡Œæ··åˆæœç´¢
    retrieve_info, question, raw_results = await SearchService().execute_hybrid_search(
        **search_params, 
        memory_config=memory_config
    )
```

**è§¦å‘æ—¶æœº**ï¼šç”¨æˆ·æé—®åï¼ŒLangGraph Read Flow çš„ç¬¬ä¸€ä¸ªèŠ‚ç‚¹

---

## ğŸ“‹ å®Œæ•´è°ƒç”¨é“¾

### å±‚çº§ 1ï¼šSummary Nodesï¼ˆLangGraph èŠ‚ç‚¹ï¼‰

**æ–‡ä»¶**ï¼š[`summary_nodes.py`](https://github.com/qudi17/MemoryBear/blob/main/api/app/core/memory/agent/langgraph_graph/nodes/summary_nodes.py)

```
Input_Summary (L178)
    â†“
SearchService().execute_hybrid_search()
    â†“
retrieve_info (clean content)
    â†“
summary_prompt() â†’ LLM â†’ Answer
```

**å…³é”®ä»£ç **ï¼š
```python
# ç¬¬ 178-200 è¡Œ
try:
    retrieve_info, question, raw_results = await SearchService().execute_hybrid_search(
        **search_params,
        memory_config=memory_config
    )
except Exception as e:
    logger.error(f"Input_Summary: hybrid_search failed: {e}")
    retrieve_info, question, raw_results = "", data, []
```

**æœç´¢å‚æ•°**ï¼š
- `end_user_id`: ç”¨æˆ· IDï¼ˆè¿‡æ»¤æ¡ä»¶ï¼‰
- `question`: ç”¨æˆ·é—®é¢˜
- `return_raw_results`: Trueï¼ˆè¿”å›åŸå§‹ç»“æœï¼‰
- `include`: ["summaries"]ï¼ˆåªæœç´¢ summary èŠ‚ç‚¹ï¼‰
- `memory_config`: è®°å¿†é…ç½®å¯¹è±¡

---

### å±‚çº§ 2ï¼šSearchServiceï¼ˆæœç´¢æœåŠ¡ï¼‰

**æ–‡ä»¶**ï¼š[`app/core/memory/agent/services/search_service.py`](https://github.com/qudi17/MemoryBear/blob/main/api/app/core/memory/agent/services/search_service.py)

**æ ¸å¿ƒæ–¹æ³•**ï¼š`execute_hybrid_search()` (L89-L196)

```python
async def execute_hybrid_search(
    self,
    end_user_id: str,
    question: str,
    limit: int = 5,
    search_type: str = "hybrid",
    include: Optional[List[str]] = None,
    rerank_alpha: float = 0.4,
    output_path: str = "search_results.json",
    return_raw_results: bool = False,
    memory_config = None
) -> Tuple[str, str, Optional[dict]]:
```

**å¤„ç†æµç¨‹**ï¼š
```
1. clean_query() - æ¸…ç†å’Œè½¬ä¹‰æŸ¥è¯¢
   â†“
2. run_hybrid_search() - æ‰§è¡Œæ··åˆæœç´¢
   â†“
3. extract_content_from_result() - æå–å†…å®¹
   â†“
4. return (clean_content, cleaned_query, raw_results)
```

**å…³é”®ä»£ç **ï¼š
```python
# ç¬¬ 122-153 è¡Œï¼šæå–ç»“æœ
answer_list = []

# Priority order: summaries first (most contextual)
priority_order = ['summaries', 'statements', 'chunks', 'entities']

for category in priority_order:
    if category in include and category in reranked_results:
        category_results = reranked_results[category]
        answer_list.extend(category_results)

# ç¬¬ 155-160 è¡Œï¼šæå–å¹²å‡€å†…å®¹
content_list = [
    self.extract_content_from_result(ans) 
    for ans in answer_list
]

clean_content = '\n'.join([c for c in content_list if c])
```

**å†…å®¹æå–è§„åˆ™**ï¼š
| èŠ‚ç‚¹ç±»å‹ | æå–å­—æ®µ |
|---------|---------|
| Statements | `statement` |
| Summaries | `content` |
| Chunks | `content` |
| Entities | `name` + `fact_summary` (å·²æ³¨é‡Š) |

---

### å±‚çº§ 3ï¼šrun_hybrid_searchï¼ˆæ ¸å¿ƒæœç´¢å‡½æ•°ï¼‰

**æ–‡ä»¶**ï¼š[`app/core/memory/src/search.py`](https://github.com/qudi17/MemoryBear/blob/main/api/app/core/memory/src/search.py)

**è°ƒç”¨**ï¼š
```python
from app.core.memory.src.search import run_hybrid_search

answer = await run_hybrid_search(
    query_text=cleaned_query,
    search_type=search_type,
    end_user_id=end_user_id,
    limit=limit,
    include=include,
    output_path=output_path,
    memory_config=memory_config,
    rerank_alpha=rerank_alpha
)
```

**åŠŸèƒ½**ï¼šåè°ƒå…³é”®è¯æœç´¢å’Œè¯­ä¹‰æœç´¢

---

### å±‚çº§ 4ï¼šHybridSearchStrategyï¼ˆæ··åˆæœç´¢ç­–ç•¥ï¼‰

**æ–‡ä»¶**ï¼š[`app/core/memory/storage_services/search/hybrid_search.py`](https://github.com/qudi17/MemoryBear/blob/main/api/app/core/memory/storage_services/search/hybrid_search.py)

**æ ¸å¿ƒæ–¹æ³•**ï¼š`search()` (è¢«æ³¨é‡Šï¼Œä½¿ç”¨æ—§æ¶æ„)

**å½“å‰æ¶æ„**ï¼š
```python
# æ—§ä»£ç å·²æ³¨é‡Šï¼Œæ–°æ¶æ„åœ¨ app/core/memory/src/search.py
# class HybridSearchStrategy(SearchStrategy):
#     async def search(self, query_text, ...):
#         # å¹¶è¡Œæ‰§è¡Œå…³é”®è¯æœç´¢å’Œè¯­ä¹‰æœç´¢
#         keyword_result = await self.keyword_strategy.search(...)
#         semantic_result = await self.semantic_strategy.search(...)
#         
#         # é‡æ’åº
#         reranked_results = self._rerank_hybrid_results(...)
#         
#         return reranked_results
```

**å­ç­–ç•¥**ï¼š
- `KeywordSearchStrategy` - å…³é”®è¯æœç´¢ï¼ˆBM25ï¼‰
- `SemanticSearchStrategy` - è¯­ä¹‰æœç´¢ï¼ˆå‘é‡ï¼‰

---

### å±‚çº§ 5ï¼šå­˜å‚¨å±‚ï¼ˆNeo4j + Vector DBï¼‰

**ç›®å½•**ï¼š[`app/core/memory/storage_services/search/`](https://github.com/qudi17/MemoryBear/tree/main/api/app/core/memory/storage_services/search)

**æ–‡ä»¶ç»“æ„**ï¼š
```
search/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ hybrid_search.py       # æ··åˆæœç´¢ï¼ˆæ—§æ¶æ„ï¼‰
â”œâ”€â”€ keyword_search.py      # å…³é”®è¯æœç´¢
â”œâ”€â”€ semantic_search.py     # è¯­ä¹‰æœç´¢
â”œâ”€â”€ search_strategy.py     # æœç´¢ç­–ç•¥åŸºç±»
â””â”€â”€ search_service.py      # æœç´¢æœåŠ¡
```

**å­˜å‚¨åç«¯**ï¼š
- **Neo4j**ï¼šçŸ¥è¯†å›¾è°±ï¼ˆentities, statementsï¼‰
- **Vector DB**ï¼šå‘é‡æ•°æ®åº“ï¼ˆchunks, summariesï¼‰
- **Redis**ï¼šçŸ­æœŸç¼“å­˜

---

## ğŸ“Š å®Œæ•´æµç¨‹å›¾

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant Input as Input_Summary Node
    participant Search as SearchService
    participant Hybrid as run_hybrid_search
    participant Keyword as Keyword Search
    participant Semantic as Semantic Search
    participant Neo4j as Neo4j
    participant Vector as Vector DB
    participant LLM as LLM
    
    User->>Input: æé—®
    Input->>Search: execute_hybrid_search()
    Search->>Search: clean_query()
    Search->>Hybrid: run_hybrid_search()
    
    par å¹¶è¡Œæœç´¢
        Hybrid->>Keyword: BM25 æœç´¢
        Keyword->>Neo4j: Cypher query
        Neo4j-->>Keyword: å…³é”®è¯ç»“æœ
        
        Hybrid->>Semantic: å‘é‡æœç´¢
        Semantic->>Vector: å‘é‡ç›¸ä¼¼åº¦
        Vector-->>Semantic: è¯­ä¹‰ç»“æœ
    end
    
    Hybrid->>Hybrid: é‡æ’åºç»“æœ
    Hybrid-->>Search: åˆå¹¶ç»“æœ
    
    Search->>Search: extract_content_from_result()
    Search-->>Input: retrieve_info (clean content)
    
    Input->>LLM: summary_prompt(retrieve_info)
    LLM-->>Input: answer
    
    Input-->>User: è¿”å›ç­”æ¡ˆ
```

---

## ğŸ” å…³é”®æ•°æ®ç»“æ„

### æœç´¢ç»“æœæ ¼å¼

```python
{
    "reranked_results": {
        "summaries": [
            {
                "content": "æ€»ç»“å†…å®¹",
                "score": 0.95,
                "created_at": "2026-02-28T10:00:00"
            }
        ],
        "statements": [...],
        "chunks": [...],
        "entities": [...]
    }
}
```

### æå–åå†…å®¹

```python
clean_content = """
æ€»ç»“å†…å®¹ 1
æ€»ç»“å†…å®¹ 2
é™ˆè¿°å†…å®¹ 3
...
"""
```

### LLM è¾“å…¥

```python
system_prompt = await template_service.render_template(
    template_name='Retrieve_Summary_prompt.jinja2',
    operation_name='input_summary',
    query=user_question,
    retrieve_info=clean_content,
    history=conversation_history
)

# LLM è¾“å‡º
{
    "query_answer": "åŸºäºæ£€ç´¢å†…å®¹çš„å›ç­”"
}
```

---

## ğŸ¯ æœç´¢ç­–ç•¥å¯¹æ¯”

### ä¸‰ç§æœç´¢ç±»å‹

| ç±»å‹ | ä¼˜ç‚¹ | ç¼ºç‚¹ | ä½¿ç”¨åœºæ™¯ |
|------|------|------|---------|
| **Keyword (BM25)** | ç²¾ç¡®åŒ¹é…æœ¯è¯­ | æ— æ³•ç†è§£è¯­ä¹‰ | å·²çŸ¥ä¸“æœ‰åè¯ |
| **Semantic (Vector)** | ç†è§£æ¦‚å¿µ | å¯èƒ½é”™è¿‡ç²¾ç¡®åŒ¹é… | æ¦‚å¿µæ€§é—®é¢˜ |
| **Hybrid** | ä¸¤è€…å…¼é¡¾ | è®¡ç®—é‡å¤§ | é€šç”¨åœºæ™¯ |

### é‡æ’åºç®—æ³•

**Reciprocal Rank Fusion (RRF)**ï¼š
```python
def _rerank_hybrid_results(keyword_result, semantic_result, alpha=0.4):
    # æ ‡å‡†åŒ–åˆ†æ•°
    keyword_scores = normalize_scores(keyword_result)
    semantic_scores = normalize_scores(semantic_result)
    
    # èåˆåˆ†æ•°
    final_scores = alpha * keyword_scores + (1 - alpha) * semantic_scores
    
    # æ’åº
    reranked = sort_by_score(final_scores)
    
    return reranked
```

**é—å¿˜æ›²çº¿åŠ æƒ**ï¼ˆå¯é€‰ï¼‰ï¼š
```python
def apply_forgetting_curve(results, decay_rate=0.1):
    for result in results:
        age = datetime.now() - result.created_at
        decay_factor = math.exp(-decay_rate * age.days)
        result.score *= decay_factor
    return results
```

---

## ğŸ“ Prompt ä½¿ç”¨

### Retrieve_Summary_prompt.jinja2

**ä½ç½®**ï¼š[`app/core/memory/agent/utils/prompt/Retrieve_Summary_prompt.jinja2`](https://github.com/qudi17/MemoryBear/blob/main/api/app/core/memory/agent/utils/prompt/Retrieve_Summary_prompt.jinja2)

**ç”¨é€”**ï¼šåŸºäºæ£€ç´¢å†…å®¹ç”Ÿæˆç­”æ¡ˆ

**æ¨¡æ¿å˜é‡**ï¼š
- `query`: ç”¨æˆ·é—®é¢˜
- `history`: å¯¹è¯å†å²
- `retrieve_info`: æ£€ç´¢åˆ°çš„å†…å®¹

**è¾“å‡ºæ ¼å¼**ï¼š
```json
{
    "data": {
        "query": "...",
        "history": [...],
        "retrieve_info": [...]
    },
    "query_answer": "åŸºäºæ£€ç´¢çš„å›ç­”"
}
```

---

## ğŸ› ï¸ æ€§èƒ½ä¼˜åŒ–

### 1. é™åˆ¶æœç´¢èŒƒå›´

```python
search_params = {
    "include": ["summaries"]  # åªæœç´¢ summary èŠ‚ç‚¹
}
```

**æ•ˆæœ**ï¼š
- å‡å°‘æœç´¢ç»“æœæ•°é‡
- æé«˜æ£€ç´¢é€Ÿåº¦
- æé«˜ç­”æ¡ˆè´¨é‡ï¼ˆsummary æœ€ç›¸å…³ï¼‰

### 2. æŸ¥è¯¢æ¸…ç†

```python
def clean_query(query: str) -> str:
    # ç§»é™¤å¼•å·
    q = q.strip("'\"")
    
    # ç§»é™¤æ¢è¡Œ
    q = q.replace('\r', ' ').replace('\n', ' ')
    
    # Lucene è½¬ä¹‰
    q = escape_lucene_query(q)
    
    return q
```

### 3. ç»“æœå»é‡

```python
retrieve_info_str = list(set(retrieve_info_str))  # å»é‡
retrieve_info_str = '\n'.join(retrieve_info_str)  # è¿æ¥
```

---

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### å“åº”æ—¶é—´åˆ†è§£

| é˜¶æ®µ | è€—æ—¶ | å æ¯” |
|------|------|------|
| **SearchService** | ~50ms | 10% |
| **Hybrid Search** | ~300ms | 60% |
| - Keyword Search | ~100ms | 20% |
| - Semantic Search | ~200ms | 40% |
| **Reranking** | ~50ms | 10% |
| **Content Extraction** | ~10ms | 2% |
| **LLM Generation** | ~100ms | 18% |
| **æ€»è®¡** | ~500ms | 100% |

### æœç´¢ç»“æœç»Ÿè®¡

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| **å¹³å‡ç»“æœæ•°** | 5 æ¡ |
| **Summary å æ¯”** | 60% |
| **Statement å æ¯”** | 25% |
| **Chunk å æ¯”** | 10% |
| **Entity å æ¯”** | 5% |

---

## ğŸ”— ç›¸å…³ä»£ç ä½ç½®

### æ ¸å¿ƒæ–‡ä»¶

| æ–‡ä»¶ | èŒè´£ | ä»£ç è¡Œ |
|------|------|--------|
| `summary_nodes.py` | LangGraph èŠ‚ç‚¹ | L178-L200 |
| `search_service.py` | æœç´¢æœåŠ¡ | L89-L196 |
| `search.py` | æ··åˆæœç´¢åè°ƒ | - |
| `hybrid_search.py` | æ··åˆç­–ç•¥ | L1-L400 |
| `keyword_search.py` | å…³é”®è¯ç­–ç•¥ | L1-L150 |
| `semantic_search.py` | è¯­ä¹‰ç­–ç•¥ | L1-L200 |

### Prompt æ–‡ä»¶

| Prompt | ç”¨é€” | ä½ç½® |
|--------|------|------|
| `Retrieve_Summary_prompt.jinja2` | æ£€ç´¢æ€»ç»“ | `app/core/memory/agent/utils/prompt/` |
| `direct_summary_prompt.jinja2` | ç›´æ¥æ€»ç»“ | `app/core/memory/agent/utils/prompt/` |
| `summary_prompt.jinja2` | å®Œæ•´æ€»ç»“ | `app/core/memory/agent/utils/prompt/` |

---

## ğŸ’¡ å…³é”®å‘ç°

### 1. ä¼˜å…ˆçº§è®¾è®¡

**ç»“æœä¼˜å…ˆçº§**ï¼š
```
summaries > statements > chunks > entities
```

**åŸå› **ï¼š
- Summariesï¼šåˆæˆä¿¡æ¯ï¼Œæœ€ä¸Šä¸‹æ–‡ç›¸å…³
- Statementsï¼šç»“æ„åŒ–äº‹å®
- Chunksï¼šåŸå§‹æ–‡æœ¬ç‰‡æ®µ
- Entitiesï¼šå®ä½“ä¿¡æ¯ï¼Œéœ€è¦æ¨ç†

### 2. å†…å®¹æå–ç­–ç•¥

**åªæå–æœ‰æ„ä¹‰å†…å®¹**ï¼š
```python
def extract_content_from_result(result: dict) -> str:
    content_parts = []
    
    if 'statement' in result:
        content_parts.append(result['statement'])
    
    if 'content' in result:
        content_parts.append(result['content'])
    
    return '\n'.join(content_parts)
```

**ä¸¢å¼ƒ**ï¼š
- å…ƒæ•°æ®ï¼ˆscore, created_atï¼‰
- ID å­—æ®µ
- å…³ç³»ä¿¡æ¯

### 3. æ··åˆæœç´¢ä¼˜åŠ¿

**å•ä¸€æœç´¢é—®é¢˜**ï¼š
- Keywordï¼šæ— æ³•ç†è§£"AI æ˜¯ä»€ä¹ˆ"vs"ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½"
- Semanticï¼šå¯èƒ½é”™è¿‡ç²¾ç¡®æœ¯è¯­åŒ¹é…

**æ··åˆæœç´¢è§£å†³**ï¼š
```
Keyword: "äººå·¥æ™ºèƒ½" (ç²¾ç¡®åŒ¹é…)
Semantic: "AI", "æœºå™¨å­¦ä¹ " (è¯­ä¹‰ç›¸å…³)
èåˆï¼šä¸¤è€…éƒ½ä¿ç•™
```

---

## ğŸ“‹ å¾…ç ”ç©¶åˆ†æ”¯

- [ ] **Neo4j æŸ¥è¯¢ç»†èŠ‚** - Cypher æŸ¥è¯¢è¯­å¥
- [ ] **å‘é‡æ•°æ®åº“å®ç°** - ä½¿ç”¨ä»€ä¹ˆå‘é‡åº“
- [ ] **é—å¿˜æ›²çº¿å®ç°** - æ—¶é—´è¡°å‡ç®—æ³•
- [ ] **Rerank ç®—æ³•ä¼˜åŒ–** - RRF vs å…¶ä»–èåˆç®—æ³•
- [ ] **ç¼“å­˜ç­–ç•¥** - Redis ç¼“å­˜æœºåˆ¶

---

**ç ”ç©¶äºº**ï¼šJarvis  
**æ—¥æœŸ**ï¼š2026-02-28  
**æ–¹æ³•**ï¼šæ¯›çº¿å›¢ç ”ç©¶æ³•ï¼ˆä» Input_Summary å…¥å£è¿½è¸ªï¼‰  
**çŠ¶æ€**ï¼šâœ… å®Œæˆä¸»æµç¨‹ï¼Œå¾…ç ”ç©¶åˆ†æ”¯å·²æ ‡è®°
